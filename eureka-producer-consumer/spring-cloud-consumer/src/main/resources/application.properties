spring.application.name=spring-cloud-consumer
server.port=9001

#TCP三次握手队列
#client端的socket等待队列：
#当第一次握手，建立半连接状态：client 通过 connect 向 server 发出 SYN 包时，client 会维护一个 socket 队列，如果 socket 等待队列满了，而 client 也会由此返回 connection time out，只要是 client 没有收到 第二次握手SYN+ACK，3s 之后，client 会再次发送，如果依然没有收到，9s 之后会继续发送。
#
#server端的半连接队列(syn队列)：
#此时server 会维护一个 SYN 队列，半连接 syn 队列的长度为 max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog)  ，在机器的tcp_max_syn_backlog值在/proc/sys/net/ipv4/tcp_max_syn_backlog下配置，当 server 收到 client 的 SYN 包后，会进行第二次握手发送SYN＋ACK 的包加以确认，client 的 TCP 协议栈会唤醒 socket 等待队列，发出 connect 调用。
#
#server端的完全连接队列(accpet队列)：
#当第三次握手时，当server接收到ACK 报之后， 会进入一个新的叫 accept 的队列，该队列的长度为 min(backlog, somaxconn)，默认情况下，somaxconn 的值为 128，表示最多有 129 的 ESTAB 的连接等待 accept()，而 backlog 的值则应该是由 int listen(int sockfd, int backlog) 中的第二个参数指定，listen 里面的 backlog 可以有我们的应用程序去定义的。

#操作系统建立连接有两个队列，在sync_recived的时候是syn队列(又叫半连接队列，长度为 max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog))，握手完成后，会进入(accept队列)accept队列的长度参数backLog就是这儿的accept-count,
#在NioEndpoint的bind()方法中可以看到对这个操作系统serverSocket参数的这个设置。
#默认值100，指的是操作系统三次握手建立连接完成后，内核监听的处于establish状态的accpt队列中连接数，超过这个数操作系统将会refusedConnect
server.tomcat.accept-count=100
#上面的accept队列就绪后,AbstractEndpoint.Acceptor的run方法里面，会循环从accept就绪队列中拿出已经就绪的SocketChannel,同时把当前连接数+1，当使用完最后socket关闭的时候才会-1，所以这个等于是tomcat最大可以同时处理连接数
#拿到socket之后，NioEndpointd的setSocketOptions方法会把socket包装到NioChannel中，把这个nioChannel注册进自己的poller注册监听器中，这样一旦socket里面有了消息，poller收到消息了就会去读取出来
#默认值10000，同时最大连接数，当tomcat的acceptor线程发现当前tomcat内在处理的同时连接的socket超过这个数，则不再从操作系统的accept队列拿socket进来了，先进行等待
#这个参数也就是说，tomcat同时缓存的正在业务操作中和等待业务执行的连接数，业务线程200个已经使用满了，还需要等待10s才能有空闲，这个时候还可以accept进800个socket连接进行等待
#假入这个时候这800个连接的数据已经读取到缓存队列中，哪怕第9s这800个连接全部客户端自己断了，第10s业务线程一旦空闲出来，一样可以执行到之前已经读进数据待处理缓冲队列中的数据(哪怕只有空数据只有header没有任何参数值传上来)，也就是处理挤压请求数据。
server.tomcat.max-connections=10000
#这是tomcat的最小业务工作线程数，用来初始化Execute线程池大小,默认10，在AbstractEndpoint的构造方法中设置了默认值
#初始值和最大值默认都是0，来一个创建一个
server.tomcat.min-spare-threads=100
server.tomcat.max-threads=200

#-----------------------------feign gzip支持，request是指为请求的数据压缩并加上gzipheader
# 必须要引入了ApacheHttpClient才会生效,查看类FeignAcceptGzipEncodingAutoConfiguration,FeignContentGzipEncodingAutoConfiguration
# 浏览器 <---- (tomcat gzip压缩)consumer(feign gzip解压) <-- (tomcat gzip压缩)producer
# 浏览器 ----> consumer(feign gzip压缩) --> (tomcat gzip解压)producer

#我在没有引入httpClient,设置feign feign.compression.request.enabled=true，feign.compression.response.enabled=true的情况下，发现feign调用回来的gzip仍然是有效解析了的
#配置请求 GZIP 压缩
#feign.compression.request.enabled=true
##配置压缩支持的 MIME TYPE
#feign.compression.request.mime-types=text/xml,application/xml,application/json
##配置压缩数据大小的最小阀值，默认 2048=2k
#feign.compression.request.min-request-size=2048
#
##配置响应 GZIP 压缩，如果微服务返回的数据是gzip格式的，则进行支持解压后处理？
#feign.compression.response.enabled=true

#gzip开启，这个主要是针对tomcat接收端，也就是client或者浏览器，或者是其他微服务过来的调用的请求，支持request和response的gzip压缩，如果request是gzip压缩的，则解压，如果返回值满足下面条件的则压缩了再返回
#server.compression.enabled=true
#server.compression.mime-types=application/json,application/xml,text/html,text/xml,text/plain,application/javascript
##默认2k
#server.compression.min-response-size=2048



eureka.client.serviceUrl.defaultZone=http://test:test@127.0.0.1:8000/eureka/

#启动后访问http://localhost:9001/hello/myname 尝试进行远程调用

ribbon.eager-load.enabled=true

###作为服务注册到注册中心，默认true
#eureka.client.register-with-eureka=true
##作为客户端拉取服务列表,默认true
eureka.client.fetch-registry=true
#每次拉取服务列表后等待多少秒再拉取最新的，默认30s,间隔更新方法请参看DiscoveryClient.fetchRegistry
eureka.client.registry-fetch-interval-seconds=30

eureka.client.healthcheck.enabled=false

#ribbon不路由给down状态服务流程如下：
#DiscoveryClient.fetchRegistry 方法的最后会执行 onCacheRefreshed() 抛一个事件出来,监听器比如 EurekaNotificationServerListUpdater 收到事件就会把
#eurekaClient当前缓存中的最新serverList拿去覆盖 ZoneAwareLoadBalancer 中的 allServerList.然后balancer会定时ping(抽象上的)所有的这些服务，把不是Up状态的的取消。
#这样，ribbon的路由就不会路由给DOWN状态的服务了

#建议查看讲解文档：
#https://baijiahao.baidu.com/s?id=1613568636020528497&wfr=spider&for=pc
#https://www.jianshu.com/p/1bd66db5dc46
#https://blog.csdn.net/zhxdick/article/details/80234224

#
# 自动配置总入口类: RibbonAutoConfiguration,具体的整个启动过程可以参考文章：https://blog.csdn.net/qq_27529917/article/details/80981109
# RibbonAutoConfiguration中有@RibbonClients注解默认引入了Ribbon客户端注册类@Import({RibbonClientConfigurationRegistrar.class}),把相关配置信息设置为RibbonClientSpecification类定义注册到容器bean注册器中
# RibbonClientConfigurationRegistrar实现了ImportBeanDefinitionRegistrar接口，会在主容器refresh的时候调用，这个时候把对应的bean定义注册进去(这里是RibbonClientSpecification)
# SpringClientFactory中注册了配置List<RibbonClientSpecification> configurations,并用来初始化clientFactory这个RibbonClient信息工厂，configurations的values填入就在RibbonAutoConfiguration中会把刚才注册的几个RibbonClientSpecification信息放到里面
# configurations这个list包含了所有的RibbonClientSpecification定义类，包含自定义的(@RibbonClients注解用来自定义ribbon的配置类,需要指定value用于哪一个服务名，否则将对所有未指定服务名的生效)，和默认的(default开头)
# 然后SpringClientfactory在使用getInsance的时候，会去找当前serverID对应的容器，如果容器会不存在则创建该该容器并把对应的configration注册到对应的容器中实例化该容器的bean(配置的对应服务名字的loadBanlancer,IRule这些)
# 调用 http://127.0.0.1:9001/hello2/boyname 然后打断点看：NameConextedFactory.createContext(String name)，这里面就会根据serverId(key,服务名，也就是前面说的configurations中RibbonClientSpecification的配置的key，找到对应配置类进行key对应单独容器里的这些bean的实例化)
# 这样在每次getLoadBalance(ServiceId(服务名))的时候，就可以从对应的服务的clientFactory(namedContextFactory)对应的容器中找到如下配置的这些实例对象用于负债均衡等等操作:
# clientFactory(namedContextFactory) -> 一个服务名 -对应一个- context，context中有自己的一套loadbanlacer等实例，这些实例的生成类来自哪个，取决于一开始时候的初始化配置，配置可以是运用于某个实例的，没有指定实例就是运用于所有
# 通过NameConextedFactory.createContext(String name) 方法可以知道，哪个配置先生效是先加载，我们在看服务对应的内置容器的初始化过程源码，他们先加载服务名称对应的配置类，然后加载 “default .” 开头的配置类，最后加载默认的配置类。也就是我们通过 @RibbonClient 引入的配置类最先加载，然后加载后续的配置,这样有自定义的类就使用自定义类，没有就使用默认的类
# 这个服务对应的内置容器在创建好后自己refresh，把相关bean进行生成(这个时候又会促发一次RibbonClientConfigurationRegistrar，但这次是生成字容器中的bean，而不是之前主容器的触发过程了)

# 主要的Ribbon配置接口如下:
# IClientConfig ribbon客户端配置默认采用DefaultClientConfigImpl
# ILoadBalancer  负载均衡器，默认采用ZoneAvoidanceRule，能在多区环境下选出最佳区域实例进行访问
# IPing   ribbon实例的loadbalancer检查策略所用类，默认使用NoOpPing，默认所有实例可用
# IRule Ribbon的loadbalancer负载均衡策略所用类，默认采用ZoneAvoidanceRule,可在多区环境下选出最佳区域实例进行访问
# ServerList<Server>  服务实例清单维护机制，默认采用ConfigurationBasedServerList、就是直接配置一个服务器列表
# ServerListerFilter<Server> 服务实例清单过滤机制，默认采用ZonePreferenceserverlistFilter ,可以优选过滤出与请求调用方同区域的服务实例
# 可以通过在properties中<clientName(服务名)>.ribbon.<key>=<value> 对上面说的几个参数进行类设置，具体key名字请参考PropertiesFactory，这个是在EurekaRibbonClientConfiguration,或RibbonClientConfiguratio配置的时候会先去找PropertiesFactory相应的key是否已设值
# PropertiesFactory里面的这种properties设置只对和Euruka合用的时候生效，在实例化EurekaRibbonClientConfiguration的时候才会去读取这个
# 这个主要是用来定制化实现RibbonClient，这里指的客户端指的是 LoadBanlanceClient(RibbonLoadBalancerClient)->clientFactory中的cilent,和reueka结合起来用的时候clientId就是服务名
# 下面是其他全局和只指定客户端配置
#  全局：ribbon.<key>=<value> 例如： ribbon.ConnectTimeout=250 ribbon.ReadTimeout=250
#  制定客户端：
# <clientName(服务名)>.ribbon.<key>=<value>
# 具体可以配置那些参数请参考：CommonClientConfigKey
#
# Ribbon只是一个纯粹的负债均衡框架组件，当他和eurekaClient联合起来使用的时候，eureka会把以上的
#  ServerList<Server> 替换为 DiscoveryEnabledNOWSServerList,把服务清单列表叫给eureka服务治理机制来维护，
#  IPing 替换为 NIWSDiscoveryPing
#  clientId会变为eureka的服务名
#
# 服务调用不通的时候使用的容错retry机制，默认是打开的 LoadBalancerRetryProperties这个类可以看到相关配置
#spring.cloud.loadbalancer.retry.enabled=true

#
#<spring-cloud-producer服务名>.ribbon.ConnectTimeout=250 连接超时时间
#<spring-cloud-producer服务名>.ribbon.ReadTimeout=1000 请求处理超时时间
#<spring-cloud-producer服务名>.ribbon.OkToRetryOnAllOperations=true 意义是无论是请求超时或者socket read timeout都进行重试，
#<spring-cloud-producer服务名>.ribbon.MaxAutoRetriesNextServer=2 重试的时候切换实例重试最大次数，不包含一开始这个实例，这里配置2意思是可以切换到2个新的实例尝试
#<spring-cloud-producer服务名>.ribbon.MaxAutoRetries=1 对当前实例的最大重试次数
# 如上所示代表遇到访问故障的时候会进行重试,先对当前实例默认重试MaxAutoRetries次，如果不行，则切换实例，最大切换MaxAutoRetriesNextServer次还失败则返回失败
# ！！！！这里有坑注意！！ 注意开了重试的时候，对于写操作，可能会前后发起多次请求，比如ReadTimeout导致的，从而导致一个多次写入，需要在服务提供端自己做好幂等性处理
# 建议OkToRetryOnAllOperations设置为false，或者写操作关闭， 请看分析：https://www.cnblogs.com/zhangjianbin/p/7228628.html
# 更多ribbon配置也可以参考ribbon的github


#默认${spring.cloud.client.hostname}:${spring.application.name}:${server.port}:
eureka.instance.instance-id=${spring.cloud.client.ipAddress}:${server.port}


#对于开启了actutor健康检查服务上报的服务，如果当时有组件出现错误，当前注册状态为down。
#该注册服务状态同步到springcloudClient端的话，在ribbon的loadbance阶段会认为该实例不可用进行过滤掉，如果过滤后一个可用实例也没有了这个时候远程调用会报错：
#com.netflix.client.ClientException: Load balancer does not have available server for client: serviceName
#所以开启了端点health健康检查的服务要注意，中间某个依赖组件挂了比如redis挂了导致health检查路径出现问题就会导致注册服务状态为down，会导致该服务实例全部的远程调用不通

#默认的负载均衡策略是ZoneAvoidanceRule,是先选择同zone的服务器再进行轮询选择
#ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.ZoneAvoidanceRule

#使用其他或者自定义的负载均衡策略
#配置方法<SERVICE_ID或者叫clientName(用了@ribbonClient注解的话)>.ribbon.NFLoadBalancerRuleClassName,必须要配置前面这个，全局配置是无法生效的
spring-cloud-producer.ribbon.NFLoadBalancerRuleClassName=com.neo.controller.ribbonrule.CustomeRule
#spring-cloud-producer.ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RandomRule
#2）由于spring-cloud的Ribbon并没有实现netflix Ribbon的所有配置项。netflix配置全局rule方式为：ribbon.NFLoadBalancerRuleClassName=package.YourRule，spring-cloud并不支持，spring-cloud直接到服务粒度，只支持SERVICE_ID.ribbon.NFLoadBalancerRuleClassName=package.YourRule。我们可以扩展org.springframework.cloud.netflix.ribbon.PropertiesFactory修正spring cloud ribbon未能完全支持netflix ribbon配置的问题。这样我们可以将全局配置写到配置中心的application-dev.properties全局配置中，然后各个微服务还可以根据自身情况做个性化定制。但是PropertiesFactory属性均为私有，应该是spring cloud不建议在此扩展。参见https://github.com/spring-cloud/spring-cloud-netflix/issues/1741。
#3）使用spring cloud官方建议的@RibbonClient方式。

#BestAvailableRule 选择一个最小并发请求的的server,逐个考察Server，如果Server被tripped了，则忽略，在选择其中ActiveRequestsCount最小的server
#AvailabilityFilteringRule 过滤掉那些因为一直连接失败的被标记为circuit tripped的后端server，并过滤掉那些高并发的的后端server（active connections 超过配置的阈值） 使用一个AvailabilityPredicate来包含过滤server的逻辑，其实就就是检查status里记录的各个server的运行状态
#WeightedResponseTimeRule 根据响应时间分配一个weight，响应时间越长，weight越小，被选中的可能性越低。 一个后台线程定期的从status里面读取评价响应时间，为每个server计算一个weight。Weight的计算也比较简单responsetime 减去每个server自己平均的responsetime是server的权重。当刚开始运行，没有形成status时，使用roubine策略选择server。
#RetryRule 对选定的负载均衡策略机上重试机制。在一个配置时间段内当选择server不成功，则一直尝试使用subRule的方式选择一个可用的server
#RoundRobinRule roundRobin方式轮询选择server 轮询index，选择index对应位置的server
#RandomRule 随机选择一个server
#ZoneAvoidanceRule 复合判断server所在区域的性能和server的可用性选择server

#可以查看实现了IRule接口的类都是负载均衡类

#可以实现IRule接口实现一个自定义负载均衡策略

#可以利用自定义负载均衡路由策略来实现spring cloud 实践-降级、限流、滚动、灰度、AB、金丝雀等等等等
#总体思路：zuul -> hystrix -> ribbon
#在网关层就给当前用户打上标签，可以是ip，用户ID，分组或者别的任何东西,然后放到header往后传，每一层调用都要传。
#在每一层调用中用自定义IRule来根据这些标签和服务的metadata中的参数设置进行路由选择.
#自己做一个service metadata的管理服务器，在上面管理这些服务的路由服务权重等相应的参数
#如果在受到header中的标签信息传给IRule实现类呢？因为因为hystrix的存在，有线程隔离的问题，不同线程间无法用ThreadLocal进行传递，这里就可以仿造调用链监控工具sleuth的HystrixRequestVariableDefault来进行传递
#可以参考github工程：https://github.com/charlesvhe/spring-cloud-practice，文章：https://www.jianshu.com/p/37ee1e84900a

#ThreadLocal，只能在当前线程传递
#InheritableThreadLocal，可以在当前线程的子线程传递
#TransmittableThreadLocal 是Alibaba开源的、用于解决 “在使用线程池等会缓存线程的组件情况下传递ThreadLocal” 问题的 InheritableThreadLocal 扩展。若希望 TransmittableThreadLocal 在线程池与主线程间传递，需配合 TtlRunnable 和 TtlCallable 使用。